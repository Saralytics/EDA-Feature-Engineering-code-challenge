Coding Challenge
--
This Code assessment represents a coding challenge for Data Engineering roles.

Purpose
--
- Evaluate your coding abilities and your software engineering skills
- Judge your technical experience
- Understand how you design the solution 

Instructions
--
- Fork this repository by following below steps
 - Python and PySpark to be used
 - Feel free to use any libraries
 - Use a visualization library to present your analysis results.
 - Once completed plesae share the GitHub repository URL with hiring team, so they can review your work
 
Challenge 
--
In this challenge, we will use a dataset having the current job posting hosted by the City of New york which is available on the City of New York's official jobs site (https://www1.nyc.gov/jobs/index.page).

- Internal postings availble to city employees and external postings availbale to the public are included. 
- Data is accesible in the CSV file attached

This challenge is composed of following steps: 

1.Data Exploration (Use Jupyter notebook)
--
- Provide a detailed analysis of source data: Column values (eg: Numerical vs character), categorical columns, etc. 
- List of KPIs to be resolved:
  - Whats the number of jobs posting per category (Top 10)? 
  - Whats the salary distribution per job category? 
  - Is there any correlation between the higher degree and the salary?
  - Whats the job posting having the highest salary per agency? 
  - Whats the job positings average salary per agency for the last 2 years? 
  - What are the highest paid skills in the US market? 

2.Data Processing: 
-- 
- Build functions to process your dataset (Cleaning, column pre-processing, data wrangling, transformation etc) 
- Apply atleast 3 feaure engineering techniques 
- Features removal 
- Store your processed data into a target file

Expectation includes: 
--
- Test cases 
- Code Comments 
- If any deployment to be done, proposals of the deployment steps
- If you had to trigger your code, please suggest your approach. 

Technical Support:
1. Containerize ? Spark On Windows - https://towardsdatascience.com/apache-spark-on-windows-a-docker-approach-4dd05d8a7147- Should we have this?
2. Databricks community edition??
3. Azure etc?
